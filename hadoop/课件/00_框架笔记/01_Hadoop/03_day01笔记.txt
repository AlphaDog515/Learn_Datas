	
一、Hadoop
1.hadoop的初衷是采用大量的廉价机器，组成一个集群！完成大数据的存储和计算！

2.hadoop中的组件
	1.x
		HDFS： 负责大数据的存储
		Common: HDFS和MR共有的常用的工具包模块！
		MapReduce:  负责计算，负责计算资源的申请的调度！

	完成大数据的计算
	①写程序，程序需要复合计算框架的要求！
		java---->main----->运行
		MapReduce(编程模型)----->Map--Reducer
			
	②运行程序，申请计算资源(cpu+内存，磁盘IO，网络IO)
		java----->JVM------>OS----->申请计算资源
		1.0: MapReduce(编程模型)---->JobTracker----->JVM----->申请计算资源
		2.0: MapReduce(编程模型)---->jar------>运行时，将jar包中的任务，
			 提交给YARN，和YARN进行通信由YARN中的组件-----JVM------>申请计算资源
					
	1.x和2.x的区别是将资源调度和管理进行分离！由同一的资源调度平台YARN进行大数据计算资源的调度！
		提升了Hadoop的通用性！Hadoop搭建的集群中的计算资源，不仅可以运行Hadoop中的MR程序！
		也可以运行其他计算框架的程序！
			
	在hadoop不久之后，由于MR的低效性，出现了许多更为高效的计算框架！
		例如： Tez，Storm,Spark，Flink
		
		
3. 2.xhadoop的组成
	HDFS（框架）:负责大数据的存储
	YARN（框架）：负责大数据的资源调度

	MR(编程模型)：使用Hadoop制定的编程要求，编写程序，完成大数据的计算！

	
二、HDFS
	负责大数据的存储
		核心进程：
		必须进程：
			Namenode(1个)： 负责文件，名称等元数据(属性信息)的存储！【一个集群一个】
							文件名，大小，文件切分了多少块(block)，创建和修改时间等！
							
					职责： 接受客户端的请求！
						   接受DN的请求！
						   向DN分配任务！
						   
			Datanode(N个)：负责文件中数据的存储！
					职责： 负责接受NM分配的任务！
						   负责数据块(block)的管理(读，写)！
			
		可选进程：
			SecondaryNamenode(N个):  负责辅助NameNode工作！

三、MapReduce
		MapReduce(编程规范)： 程序中有Mapper(简单处理)和Reducer(合并)两个阶段
		在两个阶段分别启动若干进程负责运算 这些进程称为Task
		
		遵循MapReduce的编程规范，编写的程序，打包后，称为一个Job(任务)！
		一个job中会启动若干个Task
		
		Job需要提交到YARN上，向YARN申请计算资源，运行Job中的Task(进程)！
		
		Job会先创建一个进程MRAppMaster(mapreduce 应用管理者)，由MRAppMaster向YARN申请资源！
		MRAppMaster负责监控Job中各个Task运行情况，进行容错管理！
			
			
四、YARN
	YARN负责集群中所有计算资源的管理和调度！
	
	常见进程：	
	ResourceManager(1个): 负责整个集群所有资源的管理！
			职责：负责接受客户端的提交Job的请求！
				负责向NM分配任务！
				负责接受NM上报的信息！
	
	NodeManager(N个):  负责单台计算机所有资源的管理！
			职责：  负责和RM进行通信，上报本机中的可用资源！
					负责领取RM分配的任务！
					负责为Job中的每个Task分配计算资源！
					
					
					
	概念：
		Container（容器）:  NodeManager为Job的某个Task分配了2个CPU和2G内存的计算资源！
			为了防止当前Task在使用这些资源期间，被其他的task抢占资源！
			将计算资源，封装到一个Container中，在Container中的资源，会被暂时隔离！
			无法被其他进程所抢占！
			
			当前Task运行结束后，当前Container中的资源会被释放！允许其他task来使用！


			
	