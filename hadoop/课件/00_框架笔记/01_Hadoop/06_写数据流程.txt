复习
一、完全分布式集群的搭建
1.进程规划
	原则： ①核心进程尽量分散
		   ②同质进程尽量分散
		   
2.集群间复制
①scp
		scp -r  源文件的用户名@主机名：源文件路径 目标文件的用户名@主机名：目标文件路径  
		
		特点：  全量复制
		
②rsync		
		rsync -rvlt  源文件路径 目标文件的用户名@主机名：目标文件路径		
		源文件路径是个目录，源文件路径/，只会同步源文件目录中的内容！
		源文件路径，不仅会同步源文件目录中的内容，包括目录本身也会进行同步！
	
	
3.配置ssh免密登录
		如果A机器的a用户，希望使用b用户的身份，免密登录到B机器！
		
		操作步骤：①a用户在A机器生成一对密钥(私钥+公钥)
							ssh-keygen -t rsa
		          ②将公钥的内容，配置到b用户家目录/.ssh/authoxxx_keys
							ssh-copy-id b@B
				  ③a用户在A机器，就可以使用 ssh b@B
				  
		如果在配置时，省略了用户名，那么默认使用当前操作的用户名作为目标机器的用户名！
				[a@A] ssh B   等价于[a@A] ssh a@B 
			
			
4.两种ssh的使用方式
		①登录到目标主机，再执行命令
				[a@A] ssh B
				[a@B] jps
				
				属于Login-shell，默认读取/etc/profile文件！
				
		②在A机器，执行命令
				[a@A] ssh B jps
				属于non-Login-shell，不会读取/etc/profile文件！
				只会读取 ~/.bashrc
				
			解决：在a@B的~/.bashrc中配置source /etc/profile			
		
		注意：当前主机也要配置自己到自己的SSH免密登录！
			
		配置SSH的作用 ：
				①执行scp,rsync命令时，不需要输入密码，方便
				②在执行start-all.sh群起脚本时，需要输入密码
			
			
5. 执行群起
①start-dfs.sh 可以在任意一台机器执行

②start-yarn.sh 
		如果不在RM所配置的机器执行，那么不会启动RM
		建议： 在RM所在的机器执行群起脚本！
			   只需要配置RM所在机器到集群其他机器的SSH免密登录！

③在执行群起时，默认读取当前机器 $HADOOP_HOME/etc/hadoop/slaves文件中，当前集群配置的主机名


6.集群的时间同步
	一个集群中，每台机器的时间必须保证是同步的！
	
	主要借助linux的ntp服务执行和远程时间服务器的时间同步！
	
	保证当前机器的ntp服务是开机自启动！
			chkconfig --list ntpd
			
	使用 ntpdate  -u 时间服务器的地址





		
				 




一、HDFS
1. HDFS不支持对文件的随机写
		可以追加，但是不能修改！
		原因： 文件在HDFS上存储时，以block为基本单位存储！
			①没有提供对文件的在线寻址(打开)功能
			②文件以块形式存储，修改了一个块中的内容，就会影响当前块之后所有的块，效率低
			
2. HDFS不适合存储小文件
		根本原因：  HDFS存储了大量的小文件，会降低NN的服务能力！
		
		NN负责文件元数据(属性，块的映射)的管理，NN在运行时，必须将当前集群中存储所有文件的元数据全部加载到内存！
		NN需要大量内存！
		
		举例： 当前运行NN的机器，有64G内存，除去系统开销，分配给NN50G内存！
		
		文件a (1k), 存储到HDFS上，需要将a文件的元数据保存到NN，加载到内存
			 文件名  创建时间  所属主  所属组 权限 修改时间+ 块的映射(1块)
			150B
			
			最多存储50G/150B个文件a
				50G/150B * 1k
			 
		文件b (128M), 存储到HDFS上，需要将b文件的元数据保存到NN，加载到内存
				文件名  创建时间  所属主  所属组 权限 修改时间+块的映射(1块)
			150B
			最多存储50G/150B个文件b
				50G/150B * 128M
3. 同一个文件在同一时刻只能由一个客户端写入！

4.块大小
		块大小取决于dfs.blocksize，2.x默认为128M，1.x默认为64M
		
		默认为128M的原因，基于最佳传输损耗理论！
		
		不论对磁盘的文件进行读还是写，都需要先进行寻址！
		
		最佳传输损耗理论：在一次传输中，寻址时间占用总传输时间的1%时，本次传输的损耗最小，为最佳性价比传输！
		
		目前硬件的发展条件，普通磁盘写的速率大概为100M/S, 寻址时间一般为10ms!
		
		10ms / 1% =  1s 
		1s * 100M/S=100M
		
		块在传输时，每64K还需要校验一次，因此块大小，必须为2的n次方，最接近100M的就是128M！
		
		如果公司使用的是固态硬盘，写的速度是300M/S，将块大小调整到 256M
		如果公司使用的是固态硬盘，写的速度是500M/S，将块大小调整到 512M
		
5.块大小需要合适调节
		不能太大：  
			当前有文件a, 1G
				128M一块  1G存8块   ， 取第一块
				1G一块    1G存1块   ， 取第一块
					只需要读取a文件0-128M部分的内容
			①在一些分块读取的场景，不够灵活，会带来额外的网络消耗
			②在上传文件时，一旦发生故障，会造成资源的浪费
		
		不能太小：
			文件a,128M
			1M一块：  128个块，生成128个块的映射信息
			128M一块， 1个块，一个块的映射信息
			①块太小，同样大小的文件，会占用过多的NN的元数据空间
			②块太小，在进行读写操作时，会消耗额外的寻址时间
		
		
		
6.副本数的概念指的是最大副本数！
			具体存放几个副本需要参考DN节点的数量！每个DN节点最多只能存储一个副本！
			
7.默认块大小为128M，128M指的是块的最大大小！每个块最多存储128M的数据，如果当前块存储的数据不满128M
		存了多少数据，就占用多少的磁盘空间！
		
	一个块只属于一个文件！
	
8. shell操作命令
		hadoop fs :  既可以对本地文件系统进行操作还可以操作分布式文件系统！
		hdfs dfs :   只能操作分布式文件系统
		
		
二、客户端操作

1. 使用HDFS
		服务端：  启动NN,DN
		客户端：  使用shell客户端   hadoop fs
				  使用java客户端    
				  使用python客户端
		

		
	一、HDFS的写数据流程
	①服务端启动HDFS中的NN和DN进程
	②客户端创建一个分布式文件系统客户端，由客户端向NN发送请求，请求上传文件
	③NN处理请求，检查客户端是否有权限上传，路径是否合法等
	④检查通过，NN响应客户端可以上传
	⑤客户端根据自己设置的块大小，开始上传第一个块，默认0-128M,
	  NN根据客户端上传文件的副本数(默认为3)，根据机架感知策略选取指定数量的DN节点返回	
	⑥客户端根据返回的DN节点，请求建立传输通道
		客户端向最近(网络距离最近)的DN节点发起通道建立请求，由这个DN节点依次向通道中的(距离当前DN距离最近)
		下一个节点发送建立通道请求，各个节点发送响应 ，通道建立成功
	⑦客户端每读取64K的数据，封装为一个packet(数据包，传输的基本单位)，将packet发送到通道的下一个节点
		通道中的节点收到packet之后，落盘(检验)存储，将packet发送到通道的下一个节点！
		每个节点在收到packet后，向客户端发送ack确认消息！
		
	⑧一个块的数据传输完成之后，通道关闭，DN向NN上报消息，已经收到某个块
	⑨第一个块传输完成，第二块开始传输，依次重复⑤-⑧，直到最后一个块传输完成，NN向客户端响应传输完成！
		客户端关闭输出流
		
		
	二、异常写流程
	①-⑥见上
	⑦客户端每读取64K的数据，封装为一个packet，封装成功的packet，放入到一个队列中，
	  这个队列称为dataQuene(待发送数据包)，在发送时，先将dataQuene中的packet按顺序发送，
	  发送后再放入到ackquene(正在发送的队列)。
	  每个节点在收到packet后，向客户端发送ack确认消息！
	  如果一个packet在发送后，已经收到了所有DN返回的ack确认消息，这个packet会在ackquene中删除！
	  假如一个packet在发送后，在收到DN返回的ack确认消息时超时，传输中止，ackquene中的packet会回滚到
	  dataQuene。
	  
	  重新建立通道，剔除坏的DN节点。建立完成之后，继续传输！
	  只要有一个DN节点收到了数据，DN上报NN已经收完此块，NN就认为当前块已经传输成功！
	  NN会自动维护副本数！
	  
	三、机架感知
	2.7.2默认的策略：
	第一个副本放在本地机架的一个DN节点
	第二个副本放在本地机架的另一个DN节点
			本地机架的网络拓扑举例最多为2，速度快！
	第三个副本放在其他机架的一个DN节点
			为了安全性

	tomcat服务器日志 
	数据库服务器mysql数据    客户端()


	  
	  