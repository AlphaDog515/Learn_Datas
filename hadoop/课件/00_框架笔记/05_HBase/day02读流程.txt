一、HBase
	HBase是一个基于Hadoop的分布式可扩展的，可以创建十亿级行*百万列的大表的，并对大表
	提供实时随机读写的NoSQL数据库！
		
特点： 
	①实时
		因为HBase在设计时，基于列族存储，列式存储对大数据的检索效率高
		HBase采用K-V结构存储，即便数据量再大，也可以方便检索一条记录
		HBase采取了LSM树作为数据的存储模型，在检索数据时，效率高
		HBase会占用大量的内存，提前缓存部分数据(BlockCache)
		HBase还采取了例如布隆过滤器等提高查询效率的一些其他组件
				
	②随机读写		
		HBase基于HDFS完成数据的读写！
		本质上不能随机写，因为HDFS不支持随机写，只支持追加写！
		
		追加写+时间戳(版本控制)
		
		当客户端发起update/delete等操作时，以追加的形式向表中添加一条新的记录！
		但是每次客户端在查询时，只返回时间戳最大的记录，因此达到更新和删除的效果！
				

二、HBase的安装
1.环境
	安装了JDK，安装了Hadoop，安装Zookeeper
		
2.配置
	配置 conf/hbase-env.sh，配置一些环境变量信息，包括各个进程启动后JVM堆的参数！
	配置conf/hbase-site.xml，配置用户自定义的一些参数，这些参数可以覆盖hbase-default.xml中同名的参数！
		
3.启动
	启动master:  hbase-deamon.sh start master
	启动regionserver:  hbase-deamon.sh start regionserver
	
	群起： 
		配置 conf/regionservers，在此文件中编辑集群中所有的主机名
			
		可以使用hbase-daemons.sh start regionserver群起regionserver
		也可以使用start-hbase.sh和stop-hbase.sh启动和关闭集群！
			
三、客户的操作
1.启动客户端
	hbase shell
		
2.查询帮助
	help :  查看当前hbase客户端所有命令的帮助
	help '命令'：  查看某个具体命令的帮助
	help '组名'：  查看某个组命令的帮助
		
	exit: 退出客户端
		
3.库操作
	list_namespaces: 查看所有库
	create_namespaces 库名： 创建库
	delete_namespaces 库名： 删除库，只能删除空库
		
4.表操作
	create 表名  列族名：  创建表时至少需要指定一个列族
	delete 表名：  删除表
	truncate 表名： 清空表
	alter 表名  列族名： 修改表
	describe 表名： 查看表的描述
	
	is_enable 表名: 判断表是否启用
	is_disable 表名: 判断表是否启用
	
	enable 表名： 启动表
	disable 表名：禁用表
	
	只有表启用后，才能向表中插入数据！
		
5.数据操作
	put  表名 列名(列族:列名) rowkey value [ts] : 新增或修改
	delete 表名  rowkey [列族|列名] [ts]: 删除数据
	get  表名  rowkey： 查询单行
	scan 表名  {STARTROW=> xxx, STOPROW=> xxx, LIMIT=>X} : 查询多行
		
	hbase shell主要用来测试！一般是自己使用HBase提供的JAVAAPI编写应用程序，
	使用应用程序，供客户读写数据！

	
四、原理
1.进程组成
	master(1个)： 负责对表的增删改查
		master负责分配region到regionserver，自动监控rs的状态
			 
		在一个集群中，工作状态的master只能有一个，可以有多个备用的！
			
	regionserver:  负责接受客户端的请求，对数据进行读写操作！
				   负责对region进行处理，例如region的切分和合并！
	
	zookeeper: hbase需要依赖zookeeper保存一些元数据信息！
		
2.regionserver的架构
	regionserver负责接受客户端的请求，对数据进行读写操作！
	
	一个region由一个regionserver负责！
	一个regionserer可以同时负责多个region的请求！
	
	regionserver中有以下组件：
		①一个regionserver有一个WAL对象，这个WAL对象负责当前regionserver的预写日志！
			预写日志主要为了防止memstore中的数据没有及时刷写到磁盘时，丢失，
			如果丢失可以使用预写日志恢复！
		
		②每个region都有多个列族，每个列族会创建一个store对象，一个store对象会维持
			一个memstore(写缓冲区)存储数据，并且在这个列族的目录中有多少个文件，
			就会创建多少个storefile对象，对应文件！
			
		③blockcache(读缓存): 客户端经常查询的数据，会放入到blockcache中，如果blockcache中
			有对应的数据，就不会再扫描storefile！
				
3.写流程
	找插入数据对应的rs:
		①请求zookeeper，查询 /hbase/meta-region-server 节点，获取meta表所在的rs
		②向meta表所在的rs发送读请求，将读取到的内容缓存到客户端本地，此后就不需要频繁查询meta表
		③从meta表中，根据region和regionserver的对应关系，找到rowkey所属的region的regionserver
	
	写入数据：
		④向regionserver发put请求，regionserver会使用WAL对象记录写请求，
			将写的数据，存储在memstore中
		⑤响应客户端，写操作完成
		

	写入数据的微观流程：
		①尝试尽可能获取多个锁，至少需要获取一把
		②如果当前数据没有设置时间戳，更新时间戳
		③构建WAL对象
		④写入WAL对象的buffer中，但是并不sync到磁盘
		⑤写入memstore
		⑥将WAL对象buffer中的数据sync到磁盘WAL文件
		⑦滚动MVCC版本号，滚动后，客户端就可以查询到数据
		⑧如果在整个写入过程中发生异常，此时，会将已经写入到memstore中的数据回滚！
		

一、读流程
找读取数据对应的rs:
	①请求zookeeper，查询 /hbase/meta-region-server 节点，获取meta表所在的rs
	②向meta表所在的rs发送读请求，将读取到的内容缓存到客户端本地，
		此后就不需要频繁查询meta表
	③从meta表中，根据region和regionserver的对应关系，找到rowkey所属的region的regionserver
		
读取数据：
	读取的数据存储在列族(store)中！列族在HDFS上就是一个目录，
	这个目录下存储了很多文件(storefile)数据如果是刚写入到store中，还没有刷写到磁盘，
	当前数据就存储在memstore中，有可能这个列的历史版本的数据已经刷写到磁盘存在storefile中，
	在扫描时，需要既扫memstore，又扫磁盘上的storefile，扫描出当前列的所有版本的数据，
	从这些数据中挑选出ts最大的返回！
	
	如果扫描历史版本的数据，是扫storefile，那么会发送磁盘IO，效率低，因此可以把扫描到的数据
	所在的块(block)缓存到内存中，在内存中保存缓存块的区域，称为blockcache!
	
	在以后的查询中，如果查询的数据在blockcache中有，那么就不需要再扫描storefile了！如果没有，
	再扫描storefile，将数据所在的block缓存到blockcache!
	
	Blockcache在RS中的读缓存，blockcache默认大小为当前RS所在堆缓存的40%，有LRU的回收策略！
	
	block不是HDFS上中的block，是HFile中的block(64k)!
	
-------------------------------------------
get t1,r1  : 
	扫描r1所在region的所有列族的memstore，从中找r1行的所有列的每个版本的最近数据
	扫描r1所在region的所有列族的storefile，从中找r1行的所有列的每个版本的历史数据
	将最近的数据和历史数据，汇总，挑选每个列最新的数据！
	将刚刚扫描storefile数据所在的block，缓存到blockcache中
		
put t1,r1,cf1:name,jack: 当对数据作了修改时，此时blockcache中缓存就失效了！【时间戳不一样】
		
scan t1 ,{STARTROW=>r1,STOPROW=>r4}: 扫描r1到r3行
	扫描r1所在region的所有列族的memstore，从中找r1-r3行的所有列的每个版本的最近数据
	扫描r1所在region的所有列族的storefile，从中找r2-r3行的所有列的每个版本的历史数据
	从blockcache中扫描r1行所有的数据
	
	将刚刚扫描storefile数据所在的block，缓存到blockcache中
		
二、VERSIONS
1. 每个不同时间戳的cell就是一个版本，时间戳就是版本
2. 可以设置列族的VERSIONS属性，当执行flush操作时，put的记录
		会根据时间戳选择最新的VERSIONS个版本的数据flush到磁盘中！
		
		每次flush，最多flush VERSIONS个版本的数据！
		
		
		
		

		